"""""
from huggingface_hub import hf_hub_download
from llama_cpp import Llama

# Download model (only runs once, then uses cache)
print("Downloading model...")
model_path = hf_hub_download(
    repo_id="INSAIT-Institute/BgGPT-Gemma-2-9B-IT-v1.0-GGUF",
    filename="BgGPT-Gemma-2-9B-IT-v1.0.Q4_K_M.gguf"
)

# Load model
print("Loading model...")
llm = Llama(model_path=model_path, n_ctx=2048, n_threads=4, verbose=False)

# Check facts
def check_fact(claim):
    prompt = f"Ğ’ÑÑ€Ğ½Ğ¾ Ğ»Ğ¸ Ğµ ÑĞ»ĞµĞ´Ğ½Ğ¾Ñ‚Ğ¾: {claim}\nĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€ (Ğ’ÑÑ€Ğ½Ğ¾/ĞĞµĞ²ÑÑ€Ğ½Ğ¾ Ñ % ÑƒĞ²ĞµÑ€ĞµĞ½Ğ¾ÑÑ‚):"
    output = llm(prompt, max_tokens=50, temperature=0.3)
    return output['choices'][0]['text'].strip()

# Test
print(check_fact("ĞĞµĞ±ĞµÑ‚Ğ¾ Ğµ ÑĞ¸Ğ½ÑŒĞ¾."))
"""
# from llama_cpp import Llama
# import requests

# def search_web(query):
#     # Use DuckDuckGo (free, no API key)
#     url = f"https://api.duckduckgo.com/?q={query}&format=json&lang=bg"
#     response = requests.get(url)
#     data = response.json()
#     return data.get("AbstractText", "")

# def check_fact(claim):
#     # First search the web
#     search_result = search_web(claim)
    
#     # Then pass to BgGPT
#     prompt = f"""ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸ Ğ´Ğ°Ğ»Ğ¸ ÑĞ»ĞµĞ´Ğ½Ğ¾Ñ‚Ğ¾ Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ Ğµ Ğ²ÑÑ€Ğ½Ğ¾.
    
# Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚: {search_result}
# Ğ¢Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ: {claim}

# ĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€ (Ğ’ÑÑ€Ğ½Ğ¾/ĞĞµĞ²ÑÑ€Ğ½Ğ¾ Ñ % ÑƒĞ²ĞµÑ€ĞµĞ½Ğ¾ÑÑ‚):"""
    
#     output = llm(prompt, max_tokens=100, temperature=0.3)
#     return output['choices'][0]['text'].strip()











# from huggingface_hub import hf_hub_download
# from llama_cpp import Llama
# from duckduckgo_search import DDGS

# # â”€â”€ 1. Install this first in terminal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # pip install duckduckgo-search

# # â”€â”€ 2. Download model (only once, then cached) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# print("Downloading model...")
# model_path = hf_hub_download(
#     repo_id="INSAIT-Institute/BgGPT-Gemma-2-9B-IT-v1.0-GGUF",
#     filename="BgGPT-Gemma-2-9B-IT-v1.0.Q4_K_M.gguf"
# )

# # â”€â”€ 3. Load model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# print("Loading model...")
# llm = Llama(model_path=model_path, n_ctx=2048, n_threads=4, verbose=False)
# print("Model ready!\n")

# # â”€â”€ 4. DuckDuckGo real search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def search_web(query):
#     try:
#         with DDGS() as ddgs:
#             results = list(ddgs.text(query, region="bg-bg", max_results=5))
#             if results:
#                 # Combine top 5 results into one context
#                 combined = " | ".join([r["body"] for r in results])
#                 return combined
#             return "ĞÑĞ¼Ğ° Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ."
#     except Exception as e:
#         return f"Ğ“Ñ€ĞµÑˆĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚ÑŠÑ€ÑĞµĞ½Ğµ: {str(e)}"

# # â”€â”€ 5. Fact check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def check_fact(claim):
#     print(f"ğŸ” Searching: {claim}")
#     search_result = search_web(claim)
#     print(f"ğŸ“„ Found: {search_result[:200]}...\n")  # Show first 200 chars

#     prompt = f"""Ğ¢Ğ¸ ÑĞ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ·Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ñ„Ğ°ĞºÑ‚Ğ¸. Ğ˜Ğ·Ğ¿Ğ¾Ğ»Ğ·Ğ²Ğ°Ğ¹ Ğ¡ĞĞœĞ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ÑÑ‚Ğ° Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚ Ğ¿Ğ¾-Ğ´Ğ¾Ğ»Ñƒ, Ğ·Ğ° Ğ´Ğ° Ğ¿Ñ€ĞµÑ†ĞµĞ½Ğ¸Ñˆ Ğ´Ğ°Ğ»Ğ¸ Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸ĞµÑ‚Ğ¾ Ğµ Ğ²ÑÑ€Ğ½Ğ¾.

# Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚: {search_result}

# Ğ¢Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ: {claim}

# ĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ Ğ² ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚:
# Verdict: Ğ’ÑÑ€Ğ½Ğ¾/ĞĞµĞ²ÑÑ€Ğ½Ğ¾/ĞĞµÑÑĞ½Ğ¾
# Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ¾ÑÑ‚: X%
# ĞĞ±ÑÑĞ½ĞµĞ½Ğ¸Ğµ: (Ğ¾Ğ±ÑÑĞ½Ğ¸ Ğ·Ğ°Ñ‰Ğ¾, Ğ±Ğ°Ğ·Ğ¸Ñ€Ğ°Ğ½Ğ¾ Ğ½Ğ° Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ°Ñ‚Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ)

# ĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€:"""

#     output = llm(prompt, max_tokens=300, temperature=0.3)
#     return output['choices'][0]['text'].strip()

# # â”€â”€ 6. Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# while True:
#     print("=" * 50)
#     claim = input("Ğ’ÑŠĞ²ĞµĞ´Ğ¸ Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ (Ğ¸Ğ»Ğ¸ 'exit' Ğ·Ğ° Ğ¸Ğ·Ñ…Ğ¾Ğ´): ")
    
#     if claim.lower() == "exit":
#         print("Ğ”Ğ¾Ğ²Ğ¸Ğ¶Ğ´Ğ°Ğ½Ğµ!")
#         break

#     result = check_fact(claim)
#     print(f"\nâœ… Ğ ĞµĞ·ÑƒĞ»Ñ‚Ğ°Ñ‚:\n{result}\n")



from huggingface_hub import hf_hub_download
from llama_cpp import Llama
import requests

SERPER_API_KEY = "3c6cba844457eff753d0c9cfd8cce7ffbf4b090e"  # paste your key here

# â”€â”€ 1. Download model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Downloading model...")
model_path = hf_hub_download(
    repo_id="INSAIT-Institute/BgGPT-Gemma-2-9B-IT-v1.0-GGUF",
    filename="BgGPT-Gemma-2-9B-IT-v1.0.Q4_K_M.gguf"
)

# â”€â”€ 2. Load model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Loading model...")
llm = Llama(model_path=model_path, n_ctx=2048, n_threads=4, verbose=False)
print("Model ready!\n")

# â”€â”€ 3. Google Search via Serper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_web(query):
    try:
        response = requests.post(
            "https://google.serper.dev/search",
            headers={
                "X-API-KEY": SERPER_API_KEY,
                "Content-Type": "application/json"
            },
            json={"q": query, "gl": "bg", "hl": "bg", "num": 5}
        )
        data = response.json()

        results = []

        # Get answer box if available (most accurate)
        if data.get("answerBox"):
            box = data["answerBox"]
            if box.get("answer"):
                results.append(f"Ğ”Ğ¸Ñ€ĞµĞºÑ‚ĞµĞ½ Ğ¾Ñ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€: {box['answer']}")
            if box.get("snippet"):
                results.append(f"ĞĞ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ: {box['snippet']}")

        # Get top organic results
        for r in data.get("organic", [])[:4]:
            if r.get("snippet"):
                results.append(r["snippet"])

        return " | ".join(results) if results else "ĞÑĞ¼Ğ° Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ."

    except Exception as e:
        return f"Ğ“Ñ€ĞµÑˆĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‚ÑŠÑ€ÑĞµĞ½Ğµ: {str(e)}"

# â”€â”€ 4. Fact check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_fact(claim):
    print(f"ğŸ” Ğ¢ÑŠÑ€ÑÑ: {claim}")
    search_result = search_web(claim)
    print(f"ğŸ“„ ĞĞ°Ğ¼ĞµÑ€ĞµĞ½Ğ¾: {search_result[:300]}...\n")

    prompt = f"""Ğ¢Ğ¸ ÑĞ¸ ÑÑ‚Ñ€Ğ¾Ğ³Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ·Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ñ„Ğ°ĞºÑ‚Ğ¸. Ğ˜Ğ·Ğ¿Ğ¾Ğ»Ğ·Ğ²Ğ°Ğ¹ Ğ¡ĞĞœĞ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ÑÑ‚Ğ° Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚.

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- ĞĞºĞ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ÑÑ‚Ğ° Ğ¿Ğ¾Ñ‚Ğ²ÑŠÑ€Ğ¶Ğ´Ğ°Ğ²Ğ° Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸ĞµÑ‚Ğ¾ -> Ğ’ÑÑ€Ğ½Ğ¾
- ĞĞºĞ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ÑÑ‚Ğ° Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸ Ğ½Ğ° Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸ĞµÑ‚Ğ¾ -> ĞĞµĞ²ÑÑ€Ğ½Ğ¾
- "ĞĞµÑÑĞ½Ğ¾" Ğµ Ğ—ĞĞ‘Ğ ĞĞĞ•ĞĞ
- Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ¾ÑÑ‚Ñ‚Ğ° Ñ‚Ñ€ÑĞ±Ğ²Ğ° Ğ´Ğ° Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ 70% Ğ¸ 100%

Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚: {search_result}

Ğ¢Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ: {claim}

ĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ Ğ¢ĞĞ§ĞĞ Ñ‚Ğ°ĞºĞ°:
Verdict: Ğ’ÑÑ€Ğ½Ğ¾/ĞĞµĞ²ÑÑ€Ğ½Ğ¾
Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ¾ÑÑ‚: X%
ĞĞ±ÑÑĞ½ĞµĞ½Ğ¸Ğµ: (1-2 Ğ¸Ğ·Ñ€ĞµÑ‡ĞµĞ½Ğ¸Ñ)

ĞÑ‚Ğ³Ğ¾Ğ²Ğ¾Ñ€:"""

    output = llm(prompt, max_tokens=300, temperature=0.1)
    return output['choices'][0]['text'].strip()

# â”€â”€ 5. Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
while True:
    print("=" * 50)
    claim = input("Ğ’ÑŠĞ²ĞµĞ´Ğ¸ Ñ‚Ğ²ÑŠÑ€Ğ´ĞµĞ½Ğ¸Ğµ (Ğ¸Ğ»Ğ¸ 'exit' Ğ·Ğ° Ğ¸Ğ·Ñ…Ğ¾Ğ´): ")

    if claim.lower() == "exit":
        print("Ğ”Ğ¾Ğ²Ğ¸Ğ¶Ğ´Ğ°Ğ½Ğµ!")
        break

    result = check_fact(claim)
    print(f"\nâœ… Ğ ĞµĞ·ÑƒĞ»Ñ‚Ğ°Ñ‚:\n{result}\n")